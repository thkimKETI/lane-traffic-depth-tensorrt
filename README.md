# ğŸš˜ Lane, Traffic Object, and Depth Estimation on Jetson with TensorRT

**Real-time lane detection, traffic sign/light recognition, and monocular depth estimation using TensorRT on NVIDIA Jetson.**  
Developed as part of the [KIAT] Embedded AI-based Full Autonomous Driving (Level 4) SW and MaaS Technology Development Project.

<div align="center">
  <img src="./assets/demo.gif" width="600">
</div>

---

## ğŸ§  Overview

This repository provides three major perception modules for autonomous driving:

- **Lane Detection**: Lightweight, anchor-based multi-lane detector  
- **Traffic Infrastructure Detection**: Real-time inference for traffic lights, signs, and road markings  
- **Monocular Depth Estimation**: CNN-based single-image depth map inference  

All models are optimized with **TensorRT** and designed to run on **NVIDIA Jetson platforms** (Orin, Xavier, etc).

---

## ğŸ–¼ï¸ Example Output

```
Display Frame:
â”œâ”€â”€ Bottom Area: RGB frame with lane + traffic infra overlay  
â””â”€â”€ Top-Right Area: Depth map (Inferno colormap)
```

---

## ğŸ“‚ Directory Structure

```
ADSW-Traffic-Perception/
â”œâ”€â”€ ADSW_Release.py                # Main script for real-time inference
â”œâ”€â”€ videos/                        # Sample video input
â”‚   â””â”€â”€ demo.mp4
â””â”€â”€ weights/                       # TensorRT engine files
    â”œâ”€â”€ object/object.engine
    â”œâ”€â”€ lane/lane.engine
    â””â”€â”€ depth/depth.engine

```

---

## âš™ï¸ Setup

### âœ… 1. Install dependencies

```bash
pip install -r requirements.txt
```

> Requires: Python 3.8+, CUDA 11+, TensorRT 8+, PyTorch (for tensor handling only)

---

### âœ… 2. Run demo

```bash
python ADSW_Release.py -v ./videos/SIHEUNG.mp4
```

You should see a display with:
- **Main frame (bottom)**: Real-time overlay with lane and traffic infra detection  
- **Depth view (top-right)**: Inferred depth using `depth.engine`

---

## ğŸ“¦ TensorRT Engine Notes

- `.engine` files are already optimized models. You must regenerate them if:
  - You change your Jetson device (e.g., from Xavier to Orin)
  - Your TensorRT or CUDA version differs from the training machine
- See [TensorRT documentation](https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html) for converting ONNX to TensorRT.

---

## ğŸ› ï¸ Supported Devices

| Jetson Device | Status      | FPS      |
|---------------|-------------|----------|
| Jetson Orin   | âœ… Supported | ~30 FPS  |
| Jetson Xavier | âœ… Supported | ~15â€“20 FPS |
| Jetson Nano   | âš ï¸ Not Recommended | Too slow |

---

## ğŸ‘¤ Maintainer

**Taehyeon Kim**  
Senior Researcher, Korea Electronics Technology Institute (KETI)  
ğŸ“§ taehyeon.kim@keti.re.kr

---

## ğŸ“œ License

This project is released under the MIT License. See `LICENSE` file for details.
